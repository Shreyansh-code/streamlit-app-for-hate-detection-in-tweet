{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\shrey\\BlockTweeter\\streamLIT\\training.1600000.processed.noemoticon.csv',\n",
    "                 encoding='ISO-8859-1', \n",
    "                 names=[\n",
    "                        'target',\n",
    "                        'id',\n",
    "                        'date',\n",
    "                        'flag',\n",
    "                        'user',\n",
    "                        'text'\n",
    "                        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1599990</th>\n",
       "      <td>4</td>\n",
       "      <td>2193579249</td>\n",
       "      <td>Tue Jun 16 08:38:59 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>razzberry5594</td>\n",
       "      <td>WOOOOO! Xbox is back</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599991</th>\n",
       "      <td>4</td>\n",
       "      <td>2193579284</td>\n",
       "      <td>Tue Jun 16 08:38:59 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>AgustinaP</td>\n",
       "      <td>@rmedina @LaTati Mmmm  That sounds absolutely ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599992</th>\n",
       "      <td>4</td>\n",
       "      <td>2193579434</td>\n",
       "      <td>Tue Jun 16 08:39:00 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>sdancingsteph</td>\n",
       "      <td>ReCoVeRiNg FrOm ThE lOnG wEeKeNd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599993</th>\n",
       "      <td>4</td>\n",
       "      <td>2193579477</td>\n",
       "      <td>Tue Jun 16 08:39:00 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ChloeAmisha</td>\n",
       "      <td>@SCOOBY_GRITBOYS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599994</th>\n",
       "      <td>4</td>\n",
       "      <td>2193579489</td>\n",
       "      <td>Tue Jun 16 08:39:00 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>EvolveTom</td>\n",
       "      <td>@Cliff_Forster Yeah, that does work better tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599995</th>\n",
       "      <td>4</td>\n",
       "      <td>2193601966</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>AmandaMarie1028</td>\n",
       "      <td>Just woke up. Having no school is the best fee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599996</th>\n",
       "      <td>4</td>\n",
       "      <td>2193601969</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>TheWDBoards</td>\n",
       "      <td>TheWDB.com - Very cool to hear old Walt interv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599997</th>\n",
       "      <td>4</td>\n",
       "      <td>2193601991</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>bpbabe</td>\n",
       "      <td>Are you ready for your MoJo Makeover? Ask me f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599998</th>\n",
       "      <td>4</td>\n",
       "      <td>2193602064</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>tinydiamondz</td>\n",
       "      <td>Happy 38th Birthday to my boo of alll time!!! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599999</th>\n",
       "      <td>4</td>\n",
       "      <td>2193602129</td>\n",
       "      <td>Tue Jun 16 08:40:50 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>RyanTrevMorris</td>\n",
       "      <td>happy #charitytuesday @theNSPCC @SparksCharity...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         target          id                          date      flag  \\\n",
       "1599990       4  2193579249  Tue Jun 16 08:38:59 PDT 2009  NO_QUERY   \n",
       "1599991       4  2193579284  Tue Jun 16 08:38:59 PDT 2009  NO_QUERY   \n",
       "1599992       4  2193579434  Tue Jun 16 08:39:00 PDT 2009  NO_QUERY   \n",
       "1599993       4  2193579477  Tue Jun 16 08:39:00 PDT 2009  NO_QUERY   \n",
       "1599994       4  2193579489  Tue Jun 16 08:39:00 PDT 2009  NO_QUERY   \n",
       "1599995       4  2193601966  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599996       4  2193601969  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599997       4  2193601991  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599998       4  2193602064  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599999       4  2193602129  Tue Jun 16 08:40:50 PDT 2009  NO_QUERY   \n",
       "\n",
       "                    user                                               text  \n",
       "1599990    razzberry5594                              WOOOOO! Xbox is back   \n",
       "1599991        AgustinaP  @rmedina @LaTati Mmmm  That sounds absolutely ...  \n",
       "1599992    sdancingsteph                  ReCoVeRiNg FrOm ThE lOnG wEeKeNd   \n",
       "1599993      ChloeAmisha                                  @SCOOBY_GRITBOYS   \n",
       "1599994        EvolveTom  @Cliff_Forster Yeah, that does work better tha...  \n",
       "1599995  AmandaMarie1028  Just woke up. Having no school is the best fee...  \n",
       "1599996      TheWDBoards  TheWDB.com - Very cool to hear old Walt interv...  \n",
       "1599997           bpbabe  Are you ready for your MoJo Makeover? Ask me f...  \n",
       "1599998     tinydiamondz  Happy 38th Birthday to my boo of alll time!!! ...  \n",
       "1599999   RyanTrevMorris  happy #charitytuesday @theNSPCC @SparksCharity...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.text.values\n",
    "y = df.target.values\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(x_train)\n",
    "\n",
    "X_train = vectorizer.transform(x_train)\n",
    "X_test = vectorizer.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It 257841\n",
      "was 558260\n",
      "rainy 433424\n",
      "and 57443\n",
      "cloudy 129399\n",
      "in 251981\n",
      "the 517082\n",
      "Windy 565913\n",
      "City 126950\n",
      "today 528707\n",
      "amp 56126\n",
      "WF 561897\n",
      "customers 142868\n",
      "had 226851\n",
      "some 486023\n",
      "serious 467402\n",
      "SAD 455284\n",
      "issues 257700\n",
      "with 566694\n",
      "them 519964\n",
      "when 562752\n",
      "is 256885\n",
      "summer 501487\n",
      "coming 132544\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# delimiters https://stackoverflow.com/questions/35221535/python-removing-delimiters-from-strings\n",
    "d = \",.!?/&-:;@'...\"\n",
    "\"[\"+\"\\\\\".join(d)+\"]\"\n",
    "\n",
    "# clean up the string\n",
    "s = x_train[0]\n",
    "s = ' '.join(w for w in re.split(\"[\"+\"\\\\\".join(d)+\"]\", s) if w)\n",
    "\n",
    "for i in s.split():\n",
    "  if len(i)>1: print(i, vectorizer.vocabulary_[i.lower()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.800309375\n"
     ]
    }
   ],
   "source": [
    "classifier = LogisticRegression(max_iter=3000)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "score = classifier.score(X_test, y_test)\n",
    "\n",
    "print(\"Accuracy:\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "Pkl_Filename = \"Pickle_LR_Model.pkl\"  \n",
    "\n",
    "with open(Pkl_Filename, 'wb') as file:  \n",
    "    pickle.dump(classifier, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_pkl = \"vector_LR_model.pkl\"\n",
    "\n",
    "with open(vect_pkl, 'wb') as file:  \n",
    "    pickle.dump(vectorizer, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet is negative\n"
     ]
    }
   ],
   "source": [
    "tweet = 'I condemn every action of Putin and hate him for raging a war’'\n",
    "vectTweet = vectorizer.transform(np.array([tweet]))  # vectorizes the tweet using our vectorizer\n",
    "\n",
    "prediction = classifier.predict(vectTweet)  # predicts class of the tweet\n",
    "print('Tweet is', 'positive' if prediction[0]==4 else 'negative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4f771c3920bce2e5fb0b4c2f206d99125e16e8aca16abc3fcfdcc81d39bdd113"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
